{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "hw3-1.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "eqeDLFn9hJQc",
        "IiusypMgjHsg",
        "Ep9UUuv6mWAr",
        "lfEPgOWPmpIg"
      ],
      "toc_visible": true,
      "mount_file_id": "1W67q6UorvwwjZXCZjR4KsD5mPa2giXJ_",
      "authorship_tag": "ABX9TyPEA1MAfyjn/lbhZ0ayVMEX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/j2cry/hw_DataScienePyLibs/blob/main/hw3_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kmtt3lH2hTIl"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import load_boston\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import r2_score as r2\n",
        "from sklearn.metrics import roc_auc_score as auc\n",
        "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eqeDLFn9hJQc"
      },
      "source": [
        "# **Задание 1**\n",
        "Импортируйте библиотеки pandas и numpy.\n",
        "Загрузите \"Boston House Prices dataset\" из встроенных наборов данных библиотеки sklearn. Создайте датафреймы X и y из этих данных.<br>\n",
        "Разбейте эти датафреймы на тренировочные (X_train, y_train) и тестовые (X_test, y_test) с помощью функции train_test_split так, чтобы размер тестовой выборки\n",
        "составлял 30% от всех данных, при этом аргумент random_state должен быть равен 42.<br>\n",
        "Создайте модель линейной регрессии под названием lr с помощью класса LinearRegression из модуля sklearn.linear_model.<br>\n",
        "Обучите модель на тренировочных данных (используйте все признаки) и сделайте предсказание на тестовых.<br>\n",
        "Вычислите R2 полученных предказаний с помощью r2_score из модуля sklearn.metrics.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-3r-YPW7hE7G",
        "outputId": "6df73874-a8cd-45b6-bed2-0bc394d5f346"
      },
      "source": [
        "boston = load_boston()\n",
        "X = pd.DataFrame(boston.data, columns=boston.feature_names)\n",
        "y = pd.DataFrame(boston.target, columns=['price'])\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "lr = LinearRegression()\n",
        "lr.fit(X_train, y_train)\n",
        "y_pred = lr.predict(X_test)\n",
        "r2(y_test, y_pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7112260057484974"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IiusypMgjHsg"
      },
      "source": [
        "# **Задание 2**\n",
        "Создайте модель под названием `model` с помощью RandomForestRegressor из модуля sklearn.ensemble.<br>\n",
        "Сделайте агрумент `n_estimators` равным 1000, `max_depth` должен быть равен 12 и `random_state` сделайте равным 42.<br>\n",
        "Обучите модель на тренировочных данных аналогично тому, как вы обучали модель LinearRegression, но при этом в метод fit вместо датафрейма y_train поставьте y_train.values[:, 0], чтобы получить из датафрейма одномерный массив Numpy,\n",
        "так как для класса RandomForestRegressor в данном методе для аргумента `y` предпочтительно применение массивов вместо датафрейма.<br>\n",
        "Сделайте предсказание на тестовых данных и посчитайте R2. Сравните с результатом из предыдущего задания.<br>\n",
        "Напишите в комментариях к коду, какая модель в данном случае работает лучше.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9NcVilFcjH7Q",
        "outputId": "f4a6dd5a-66ab-4634-caef-1a40cb8c0cea"
      },
      "source": [
        "model = RandomForestRegressor(n_estimators=1000, max_depth=12, random_state=42)\n",
        "\n",
        "model.fit(X_train, y_train.values.flatten())\n",
        "y_pred = model.predict(X_test)\n",
        "r2(y_test, y_pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8749965273218174"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8F0pYqQmlaA-"
      },
      "source": [
        "очевидно, что `RandomForestRegressor` работает ощутимо лучше"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ep9UUuv6mWAr"
      },
      "source": [
        "# ***Задание 3**\n",
        "Вызовите документацию для класса RandomForestRegressor, найдите информацию об атрибуте feature_importances_. С помощью этого атрибута найдите сумму всех показателей важности, установите, какие два признака показывают наибольшую важность.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mH1vlU9dmon6",
        "outputId": "61adac8f-ec08-41a1-9a0a-4155fd99b328"
      },
      "source": [
        "RandomForestRegressor?\n",
        "model.feature_importances_.sum()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9999999999999999"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IY8L9PQNnRju",
        "outputId": "cec6b9da-44f0-47e6-ffd5-ab98c4000baf"
      },
      "source": [
        "# текстовый вариант\n",
        "feat_imp = pd.Series(model.feature_importances_, X_train.columns)\n",
        "feat_imp.sort_values(ascending=False)[:2]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LSTAT    0.415679\n",
              "RM       0.402705\n",
              "dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "386gn7RFp-uv"
      },
      "source": [
        "# визуальный вариант\n",
        "plt.barh(X_train.columns, model.feature_importances_)\n",
        "plt.xlabel('Weight')\n",
        "plt.title('Features weights')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lfEPgOWPmpIg"
      },
      "source": [
        "# ***Задание 4**\n",
        "В этом задании мы будем работать с датасетом, с которым мы уже знакомы по домашнему заданию по библиотеке Matplotlib, это датасет Credit Card Fraud Detection.Для этого датасета мы будем решать задачу классификации - будем определять,какие из транзакциции по кредитной карте являются мошенническими.Данный датасет сильно несбалансирован (так как случаи мошенничества относительно редки),так что применение метрики accuracy не принесет пользы и не поможет выбрать лучшую модель.Мы будем вычислять AUC, то есть площадь под кривой ROC.<br>\n",
        "Импортируйте из соответствующих модулей `RandomForestClassifier`, `GridSearchCV` и `train_test_split`.<br>\n",
        "Загрузите датасет creditcard.csv и создайте датафрейм df.<br>\n",
        "С помощью метода value_counts с аргументом `normalize=True` убедитесь в том, что выборка несбалансирована.Используя метод info, проверьте, все ли столбцы содержат числовые данные и нет ли в них пропусков.Примените следующую настройку, чтобы можно было просматривать все столбцы датафрейма:\n",
        "`pd.options.display.max_columns = 100`.\n",
        "Просмотрите первые 10 строк датафрейма df.\n",
        "Создайте датафрейм X из датафрейма df, исключив столбец `Class`.\n",
        "Создайте объект `Series` под названием `y` из столбца `Class`.\n",
        "Разбейте X и y на тренировочный и тестовый наборы данных при помощи функции `train_test_split`, используя аргументы: `test_size=0.3`, `random_state=100`, `stratify=y`.\n",
        "У вас должны получиться объекты X_train, X_test, y_train и y_test.\n",
        "Просмотрите информацию о их форме.\n",
        "Для поиска по сетке параметров задайте такие параметры:\n",
        "`parameters = [{'n_estimators': [10, 15],\n",
        "'max_features': np.arange(3, 5),\n",
        "'max_depth': np.arange(4, 7)}]`<br>\n",
        "Создайте модель GridSearchCV со следующими аргументами:\n",
        "`estimator=RandomForestClassifier(random_state=100),\n",
        "param_grid=parameters,\n",
        "scoring='roc_auc',\n",
        "cv=3`.<br>\n",
        "Обучите модель на тренировочном наборе данных (может занять несколько минут).\n",
        "Просмотрите параметры лучшей модели с помощью атрибута best_params_.\n",
        "Предскажите вероятности классов с помощью полученнной модели и метода predict_proba.<br>\n",
        "Из полученного результата (массив Numpy) выберите столбец с индексом 1 (вероятность класса 1) и запишите в массив y_pred_proba. Из модуля sklearn.metrics импортируйте метрику roc_auc_score.<br>\n",
        "Вычислите AUC на тестовых данных и сравните с результатом,полученным на тренировочных данных, используя в качестве аргументов массивы y_test и y_pred_proba.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xzu28zXfmpZP"
      },
      "source": [
        "# import data\n",
        "DATA_PATH = '/content/drive/MyDrive/creditcard.csv'\n",
        "df = pd.read_csv(DATA_PATH)\n",
        "pd.options.display.max_columns = 100"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PlgEU7I6t-_1"
      },
      "source": [
        "df.value_counts(normalize=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pRsPpupKuKct"
      },
      "source": [
        "df.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6m5wMsS7uy7m"
      },
      "source": [
        "df.head(10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MNcESOdKu5j_"
      },
      "source": [
        "X = df.drop(columns='Class')\n",
        "y = df['Class']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=100, stratify=y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a3UR7q58S9dJ"
      },
      "source": [
        "X_train.shape, X_test.shape, df.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "drkbZYfzwDSx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ca66ab36-86b6-434c-e202-599ca45852af"
      },
      "source": [
        "parameters = [{'n_estimators': [10, 15], 'max_features': np.arange(3, 5), 'max_depth': np.arange(4, 7)}]\n",
        "\n",
        "model = GridSearchCV(estimator=RandomForestClassifier(random_state=100), param_grid=parameters, scoring='roc_auc', cv=3)\n",
        "model.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=3, error_score=nan,\n",
              "             estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,\n",
              "                                              class_weight=None,\n",
              "                                              criterion='gini', max_depth=None,\n",
              "                                              max_features='auto',\n",
              "                                              max_leaf_nodes=None,\n",
              "                                              max_samples=None,\n",
              "                                              min_impurity_decrease=0.0,\n",
              "                                              min_impurity_split=None,\n",
              "                                              min_samples_leaf=1,\n",
              "                                              min_samples_split=2,\n",
              "                                              min_weight_fraction_leaf=0.0,\n",
              "                                              n_estimators=100, n_jobs=None,\n",
              "                                              oob_score=False, random_state=100,\n",
              "                                              verbose=0, warm_start=False),\n",
              "             iid='deprecated', n_jobs=None,\n",
              "             param_grid=[{'max_depth': array([4, 5, 6]),\n",
              "                          'max_features': array([3, 4]),\n",
              "                          'n_estimators': [10, 15]}],\n",
              "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
              "             scoring='roc_auc', verbose=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pnE2qXMAwek7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e3515595-4bf3-450f-a4ec-f70c3bcb7e6e"
      },
      "source": [
        "model.best_params_"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'max_depth': 6, 'max_features': 3, 'n_estimators': 15}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TyrKewlaY2Lc"
      },
      "source": [
        "y_train_proba = model.predict_proba(X_train)[:, 1]\n",
        "y_pred_proba = model.predict_proba(X_test)[:, 1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c3pG3JQ0Zx_r",
        "outputId": "393290bf-0282-4dda-f581-e1a94ffafa1e"
      },
      "source": [
        "auc(y_test, y_pred_proba), auc(y_train, y_train_proba)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.9462664156037156, 0.9703527882554751)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    }
  ]
}